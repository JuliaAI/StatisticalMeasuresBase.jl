var documenterSearchIndex = {"docs":
[{"location":"tools_for_implementers/#tools","page":"Tools for Implementers","title":"Tools for Implementers","text":"","category":"section"},{"location":"tools_for_implementers/","page":"Tools for Implementers","title":"Tools for Implementers","text":"method purpose\n@trait syntactic sugar for  declaring traits\n@fix_show improve display of a measure\naggregate for explicit aggregation if multimeasure is not fit to purpose\nStatisticalMeasuresBase.skipinvalid skip NaN and missing values\nStatisticalMeasuresBase.check_numobs(y1, y2) check y1 and y2 have same number of observations\nStatisticalMeasuresBase.check_pools(y1, y2) check y1 and y2 have the same class pools\nStatisticalMeasuresBase.check_weight_support check if a measure supports specified weights\nStatisticalMeasuresBase.CompositeWeights combine weights and class_weights into single iterator\nStatisticalMeasuresBase.weighted broadcast weights over observations without aggregation\nStatisticalMeasuresBase.Wrapper{M} the abstract type for measure wrappers\n@combination generate multiple measures from a single scalar function","category":"page"},{"location":"tools_for_implementers/","page":"Tools for Implementers","title":"Tools for Implementers","text":"Table of convenience methods available for new measure type implementations","category":"page"},{"location":"tools_for_implementers/#Reference","page":"Tools for Implementers","title":"Reference","text":"","category":"section"},{"location":"tools_for_implementers/","page":"Tools for Implementers","title":"Tools for Implementers","text":"@trait\n@fix_show\nStatisticalMeasuresBase.skipinvalid\nStatisticalMeasuresBase.check_numobs\nStatisticalMeasuresBase.check_pools\nStatisticalMeasuresBase.check_weight_support\nStatisticalMeasuresBase.CompositeWeights\nStatisticalMeasuresBase.weighted\nStatisticalMeasuresBase.Wrapper\n@combination","category":"page"},{"location":"tools_for_implementers/#StatisticalMeasuresBase.@trait","page":"Tools for Implementers","title":"StatisticalMeasuresBase.@trait","text":"@trait SomeMeasureType trait1=value1 trait2=value2 ...\n\nDeclare SomeMeasureType a type whose instances are measures, and overload the specified traits to have the given values on all such instances.\n\nFor example, if AUC is a type, then\n\n@trait AUC orientation = Loss() supports_weights = true\n\nis equivalent to the declarations\n\nStatisticalMeasuresBase.is_measure(::AUC) = true\nStatisticalMeasuresBase.orientation(::AUC) = Score()\nStatisticalMeasuresBase.supports_weights(::AUC) = true\n\n\n\n\n\n","category":"macro"},{"location":"tools_for_implementers/#StatisticalMeasuresBase.@fix_show","page":"Tools for Implementers","title":"StatisticalMeasuresBase.@fix_show","text":"@fix_show constructor::T\n\nOverload Base.show to get a human readable display of all objects of the form constructor(args...; kwargs...), given an upper bound T for the type of such objects, that does not supertype any other objects.\n\nExample\n\nConsider this definition of a constructor LP:\n\nimport StatisticalMeasuresBase as API\nusing StatisticalMeasuresBase\n\nstruct LPOnScalars{T}\n    p::T\nend\nmeasure(yhat, y) = abs(yhat - y)^measure.p\n\nLP(; p=2) = multimeasure(LPOnScalars(p))\n\njulia> LP()\nmultimeasure(LPOnScalars{Int64}(2))\n\nWe fix this as follows:\n\nLPType = API.Multimeasure{<:LPOnScalars}\n@fix_show LP::LPType\n\njulia> LP()\nLP(\n  p = 2)\n\n\n\n\n\n","category":"macro"},{"location":"tools_for_implementers/#StatisticalMeasuresBase.skipinvalid","page":"Tools for Implementers","title":"StatisticalMeasuresBase.skipinvalid","text":"skipinvalid(itr; skipnan=true)\n\nReturn an iterator over the elements in itr, skipping missing and NaN values. Behavior is similar to skipmissing.\n\nIf skipnan=false, then skipinvalid is equivalent to skipmissing.\n\n\n\nskipinvalid(A, B; skipnan=true)\n\nFor vectors A and B of the same length, return a tuple of vectors (A[mask], B[mask]) where mask[i] is true if and only if A[i] and B[i] are both valid (neither missing nor NaN). Can also be called on other iterators of matching length, such as arrays, but always returns a vector. Does not remove Missing from the element types if present in the original iterators.\n\nIf skipnan=false, then NaNs are ignored.\n\n\n\n\n\n","category":"function"},{"location":"tools_for_implementers/#StatisticalMeasuresBase.check_numobs","page":"Tools for Implementers","title":"StatisticalMeasuresBase.check_numobs","text":"    check_numobs(X, Y)\n\nCheck if two objects X and Y supporting the MLJUtils.jl numobs interface have the same number of observations. If they don't, throw an exception.\n\n\n\n\n\n","category":"function"},{"location":"tools_for_implementers/#StatisticalMeasuresBase.check_pools","page":"Tools for Implementers","title":"StatisticalMeasuresBase.check_pools","text":"check_pools(A, B)\n\nIf A and B are both CategoricalArrays (or views thereof) check they have the same class pool. If both A and B are ordered, check the pools have the same ordering.\n\nIf B an abstract dictionary, check the key set of B agrees with the class pool of A, in the case A is a CategoricalArray. Otherwise, check it agrees with unique(skipmissing(A)).\n\nOtherwise perform no checks.\n\nIf a check fails throw an exception.\n\n\n\n\n\n","category":"function"},{"location":"tools_for_implementers/#StatisticalMeasuresBase.check_weight_support","page":"Tools for Implementers","title":"StatisticalMeasuresBase.check_weight_support","text":"check_weight_support(measure, weight_args...)\n\nCheck if measure supports calls of the form measure(ŷ, y, weight_args...). Will always accept nothing as one or both weight arguments. A failed check throws an exception.\n\n\n\n\n\n","category":"function"},{"location":"tools_for_implementers/#StatisticalMeasuresBase.CompositeWeights","page":"Tools for Implementers","title":"StatisticalMeasuresBase.CompositeWeights","text":"StatisticalMeasuresBase.CompositeWeights(y)\nStatisticalMeasuresBase.CompositeWeights(y, weights)\nStatisticalMeasuresBase.CompositeWeights(y, weights, class_weights)\nStatisticalMeasuresBase.CompositeWeights(y, class_weights::AbstractDict)\n\nReturn an iterator which combines, with ordinary multiplication, the specified weights and class_weights, given a target y.\n\ny = [\"a\", \"b\", \"b\", \"b\"]\nweights = [1, 2, 3, 4]\nclass_weights = Dict(\"a\"=>2, \"b\"=>1)\ncombined = StatisticalMeasuresBase.CompositeWeights(y, weights, class_weights)\n\njulia> collect(combined)\n4-element Vector{Any}:\n 2\n 2\n 3\n 4\n\nOmitted or nothing weights/class_weights are interpreted as uniform. Unless nothing, the length of weights is expected to be (at least) the number of observations in y and the keys of class_weights should include all values of y.\n\nClass weights transform missing values of y to zeros.\n\ny = [missing, \"a\", \"b\", \"b\", \"b\"]\nclass_weights = Dict(\"a\"=>2, \"b\"=>1)\ncombined = StatisticalMeasuresBase.CompositeWeights(y, class_weights)\ncollect(combined)\njulia> collect(combined)\n5-element Vector{Int64}:\n 0\n 2\n 1\n 1\n 1\n\n\n\n\n\n","category":"type"},{"location":"tools_for_implementers/#StatisticalMeasuresBase.weighted","page":"Tools for Implementers","title":"StatisticalMeasuresBase.weighted","text":"weighted([f, ] itr; weights=nothing, mode=Mean(), skipnan=false)\n\nThis method takes the same arguments and keyword arguments as aggregate but only multiplies the iterator by any specified weights and collects.  In the special case mode=RootMean(p), the weights are first replaced by their pth roots, for consistency with how aggregation works in that case.\n\nSee also aggregate\n\n\n\n\n\n","category":"function"},{"location":"tools_for_implementers/#StatisticalMeasuresBase.Wrapper","page":"Tools for Implementers","title":"StatisticalMeasuresBase.Wrapper","text":"Wrapper{M}\n\nAbstract type for measure wrappers. Here M is the atomic measure type.\n\n\n\n\n\n","category":"type"},{"location":"tools_for_implementers/#StatisticalMeasuresBase.@combination","page":"Tools for Implementers","title":"StatisticalMeasuresBase.@combination","text":"@combination SomeMeasure() = multimeasure(f)\n@combination SomeMeasure() = multimeasure(f, mode=...)\n\nAdvanced tool for generating multiple measure constructors from a single scalar function, (ŷ, y) -> f(ŷ, y). See \"Enhancements\" below for a variation for parameterized functions.\n\nAssuming f(yhat, y) is an ordinary function with scalar arguments, the above calls acts as more-or-less as if @combination were absent, but with the following differences and additional actions:\n\n1. A new concrete measure type SomeMeasureOnScalars is added: If sm = SomeMeasureOnScalars(), then sm(yhat, y) = f(yhat, y).\n\n2. Specifically, we have\n\nSomeMeasure() = multimeasure(\n    supports_missings_measure(sm),\n    mode=mode,\n) |> robust_measure |> fussy_measure\n\nso that missing scalar elements are supported, relevant argument checks are performed, and weight arguments can be nothing.\n\n3. An additional multi-target constructor is defined:\n\nMultitargetSomeMeasure(; atomic_weights=nothing) = multimeasure(\n    multimeasure(supports_missings_measure(sm), mode=mode),\n    atomic_weights=atomic_weights,\n    transform=vec∘collect,\n) |> robust_measure |> fussy_measure\n\nThis measure will have similar support for missing scalar elements and nothing weights, and will perform argument checks. It can consume some kinds of tables.\n\n4. The show method for displaying both kinds of measure is made friendlier; see   @fix_show.\n\nNote that, by construction, measure = SomeMeasure() if and only if measure isa W{<:W<:W{<:W{<:SomeMeasureOnScalars}}}, where W = StatisticalMeasuresBase.Wrapper, and measure = MultitargetSomeMeasure(; atomic_weights=wts) for some wts if and only if measure isa W{<:W{<:W{<:W{<:W{<:SomeMeasureOnScalars}}}}}.\n\nEnhancements\n\nA single parameter can added to the provided expression, corresponding to the third argument of f. Traits may be also be declared, as they apply to SomeMeasure, which are appropriately lifted to MultitargetSomeMeasure, and dropped to SomeScalarMeasure.\n\nEnhanced syntax example:\n\nf(yhat, y, tol) = abs(yhat - y)/max(abs(y), tol)\n@combination(\n    ProportionalAbsoluteDifference(; tol=eps()) = multimeasure(f),\n    observation_scitype = Continuous,     # becomes Union{Missing,Continuous}\n    orientation=Loss(),\n)\n\nFor further elucidation, see the documentation Tutorial.\n\nnote: Note\nThis marcro is experimental and its behavior is subject to change in patch and minor releases.\n\n\n\n\n\n","category":"macro"},{"location":"methods/#Methods","page":"Methods","title":"Methods","text":"","category":"section"},{"location":"methods/","page":"Methods","title":"Methods","text":"method description\nmeasurements for returning individual per-observation measurements\naggregate multipurpose measurement aggregation","category":"page"},{"location":"methods/","page":"Methods","title":"Methods","text":"The aggregate method and multimeasure wrapper take an optional aggregation mode argument, with default Mean(), whose possible values are explained below.","category":"page"},{"location":"methods/","page":"Methods","title":"Methods","text":"StatisticalMeasuresBase.AggregationMode","category":"page"},{"location":"methods/#StatisticalMeasuresBase.AggregationMode","page":"Methods","title":"StatisticalMeasuresBase.AggregationMode","text":" StatisticalMeasuresBase.AggregationMode\n\nAbstract type for modes of aggregating weighted or unweighted measurements. An aggregation mode is one of the following concrete instances of this type (when unspecified, weights are unit weights):\n\nMean(): Compute the mean value of the weighted measurements. Equivalently, compute the usual weighted mean and multiply by the average weight. To get a true weighted mean, re-scale weights to average one, or use IMean() instead.\nSum(): Compute the usual weighted sum.\nRootMean(): Compute the squares of all measurements, compute the weighted Mean() of these, and apply the square root to the result.\nRootMean(p) for some real p > 0: Compute the obvious generalization of RootMean() with RootMean() = RootMean(2).\nIMean(): Compute the usual weighted mean, which is insensitive to weight rescaling.\n\n\n\n\n\n","category":"type"},{"location":"methods/#wrappers","page":"Methods","title":"Wrappers","text":"","category":"section"},{"location":"methods/","page":"Methods","title":"Methods","text":"method description\nsupports_missings_measure(measure) wrapper to add missing value support\nmultimeasure(measure; options...) wrapper to broadcast measures over multiple observations\nfussy_measure(measure) wrapper to add strict argument checks\nrobust_measure(measure) wrapper to silently treat unsupported weights as uniform\nMeasure(m) convert a measure-like object m to StatisticalMeasuresBase.jl meausure","category":"page"},{"location":"methods/#Unwrapping","page":"Methods","title":"Unwrapping","text":"","category":"section"},{"location":"methods/","page":"Methods","title":"Methods","text":"method description\nunfussy(measure) remove fussy_measure wrap if this is outer wrap\nStatisticalMeasuresBase.unwrap(measure) remove one layer of wrapping","category":"page"},{"location":"methods/#Traits","page":"Methods","title":"Traits","text":"","category":"section"},{"location":"methods/","page":"Methods","title":"Methods","text":"The following traits, provide further information about measures:","category":"page"},{"location":"methods/","page":"Methods","title":"Methods","text":"method description\nStatisticalMeasuresBase.is_measure(measure) true if measure is known to be a StatisticalMeasuresBase.jl compliant measure\nStatisticalMeasuresBase.consumes_multiple_observations(measure) \"observations\" in the sense of MLUtils.jl\nStatisticalMeasuresBase.can_report_unaggregated(measure) true if measurements generally returns different values\nStatisticalMeasuresBase.kind_of_proxy(measure) kind of proxy for target predictions, ŷ, e.g. LearnAPI.Distribution()\nStatisticalMeasuresBase.observation_scitype(measure) upper bound on scitype of single ground truth observation; see ScientificTypes.jl\nStatisticalMeasuresBase.can_consume_tables(measure) ground truth and prediction can be some kinds of table\nStatisticalMeasuresBase.supports_weights(measure) true if per-observation weights are supported\nStatisticalMeasuresBase.supports_class_weights(measure) true if class weights are supported\nStatisticalMeasuresBase.orientation(measure) Loss(), Score() or Unoriented()\nStatisticalMeasuresBase.external_aggregation_mode(measure) One of Mean(), Sum(), etc\nStatisticalMeasuresBase.human_name(measure) human-readable name of measure","category":"page"},{"location":"methods/#Reference","page":"Methods","title":"Reference","text":"","category":"section"},{"location":"methods/","page":"Methods","title":"Methods","text":"StatisticalMeasuresBase.measurements\nStatisticalMeasuresBase.aggregate","category":"page"},{"location":"methods/#StatisticalMeasuresBase.measurements","page":"Methods","title":"StatisticalMeasuresBase.measurements","text":"measurements(measure, ŷ, y[, weights, class_weights::AbstractDict])\n\nReturn a vector of measurements, one for each observation in y, rather than a single aggregated measurement. Otherwise the behavior is the same as calling the measure directly on data.\n\nNew implementations\n\nOverloading this function for new measure types is optional. A fallback returns the aggregated measure, repeated n times, where n = MLUtils.numobs(y) (which falls back to length(y) if numobs is not implemented).  It is not typically necessary to overload measurements for wrapped measures.  All multimeasures provide the obvious fallback and other wrappers simply forward the measurements method of the atomic measure. If overloading, use the following signatures:\n\nStatisticalMeasuresBase.measurements(measure::SomeMeasureType, ŷ, y)\nStatisticalMeasuresBase.measurements(measure::SomeMeasureType, ŷ, weights)\nStatisticalMeasuresBase.measurements(measure::SomeMeasureType, ŷ, class_weights::AbstractDict)\nStatisticalMeasuresBase.measurements(measure::SomeMeasureType, ŷ, weights, class_weights)\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.aggregate","page":"Methods","title":"StatisticalMeasuresBase.aggregate","text":"aggregate(itr; weights=nothing, mode=Mean(), skipnan=false)\n\nAggregate the values generated by the iterator, itr, using the specified aggregation mode and optionally specified numerical weights.\n\nAny missing values in itr are skipped before aggregation, but will still count towards normalization factors. So, if the return type has a zero, it's as if we replace the missings with zeros.\n\nThe values to be aggregated must share a type for which +, * / and ^ (RootMean case) are defined, or can be dictionaries whose value-type is so equipped.\n\nKeyword options\n\nweights=nothing: An iterator with a length, generating Real elements, or nothing\nmode=Mean(): Options include Mean() and Sum(); see StatisticalMeasuresBase.AggregationMode for all options and their meanings. Using Mean() in conjunction with weights returns the usual weighted mean scaled by the average weight value. \nskipnan=false: Whether to skip NaN values in addition to missing values\naggregate=true: If false then itr is just multiplied by any specified weights, and collected.\n\nExample\n\nSuppose a 3-fold cross-validation algorithm delivers root mean squared errors given by errors below, and that the folds have the specified sizes. Then μ below is the appropriate error aggregate.\n\nerrors = [0.1, 0.2, 0.3]\nsizes = [200, 200, 150]\nweights = 3*sizes/sum(sizes)\n@assert mean(weights) ≈ 1\nμ = aggregate(errors; weights, mode=RootMean())\n@assert μ ≈ (200*0.1^2 + 200*0.2^2 + 150*0.3^2)/550 |> sqrt\n\n\n\naggregate(f, itr; options...)\n\nInstead, aggregate the results of broadcasting f over itr. Weight multiplication is fused with the broadcasting operation, so this method is more efficient than separately broadcasting, weighting, and aggregating.\n\nThis method has the same keyword options as above.\n\nExamples\n\nitr = [(1, 2), (2, 3), (4, 3)]\n\njulia> aggregate(t -> abs(t[1] - t[2]), itr, weights=[10, 20, 30], mode=Sum())\n60\n\n\n\n\n\n","category":"function"},{"location":"methods/#Wrappers","page":"Methods","title":"Wrappers","text":"","category":"section"},{"location":"methods/","page":"Methods","title":"Methods","text":"StatisticalMeasuresBase.supports_missings_measure\nStatisticalMeasuresBase.multimeasure\nStatisticalMeasuresBase.fussy_measure\nStatisticalMeasuresBase.robust_measure\nStatisticalMeasuresBase.Measure","category":"page"},{"location":"methods/#StatisticalMeasuresBase.supports_missings_measure","page":"Methods","title":"StatisticalMeasuresBase.supports_missings_measure","text":"supports_missings_measure(atomic_measure)\n\nReturn a new measure, measure, with the same behavior as atomic_measure, but supporting missing as a value for ŷ or y in calls like measure(ŷ, y, args...), or in applications of measurements.  Missing values are propagated by the wrapped measure (but may be skipped in subsequent wrapping or aggregation).\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.multimeasure","page":"Methods","title":"StatisticalMeasuresBase.multimeasure","text":"StatisticalMeasuresBase.multimeasure(atomic_measure; options...)\n\nReturn a new measure, called a multi-measure, which, on a prediction-target pair (ŷ, y), broadcasts atomic_measure over MLUtils.eachobs((ŷ, y)) and aggregates the result. Here ŷ and y are necessarily objects implementing the MLUtils getobs/numobs interface, such as arrays, and tables X for which Tables.istable(X) == true.\n\nAll multi-measures automatically support weights and class weights.\n\nBy default, aggregation is performed using the preferred mode for atomic_measure, i.e., StatisticalMeasuresBase.external_aggregation_mode(atomic_measure). Internally, aggregation is performed using the aggregate method.\n\nNested applications of multimeasure are useful for building measures that apply to matrices and some tables (\"multi-targets\") as well as multidimensional arrays. See the Advanced Examples below.\n\nSimple example\n\nusing StatisticalMeasuresBase\n\n# define an atomic measure:\nstruct L2OnScalars end\n(::L2OnScalars)(ŷ, y) = (ŷ - y)^2\n\njulia> StatisticalMeasuresBase.external_aggregation_mode(L2OnScalars())\nMean()\n\n# define a multimeasure:\nL2OnVectors() = StatisticalMeasuresBase.multimeasure(L2OnScalars())\n\ny = [1, 2, 3]\nŷ = [7, 6, 5]\n@assert L2OnVectors()(ŷ, y) ≈ (ŷ - y).^2 |> mean\n\nKeyword options\n\nmode=StatisticalMeasuresBase.external_aggregation_mode(atomic_measure): mode for aggregating the results of broadcasting. Possible values include Mean() and Sum(). See AggregationMode for all options and their meanings. Using Mean() in conjunction with weights returns the usual weighted mean scaled by the average weight value. .\ntransform=identity: an optional transformation applied to observations in y and ŷ before passing to each atomic_measure call. A useful value is vec∘collect which is the identity on vectors, flattens arrays, and converts the observations of some tables (it's \"rows\") to vectors. See the example below.\natomic_weights=nothing: the weights to be passed to the atomic measure, on each call to evaluate it on the pair (transform(ŷᵢ), transform(yᵢ)), for each (ŷᵢ, yᵢ) in MLUtils.eachjobs(ŷ, y). Assumes atomic_measure supports weights.\nskipnan=false: whether to skip NaN values when aggregating (missing values are always skipped)\n\nAdvanced examples\n\nBuilding on L2OnVectors defined above:\n\n# define measure for multi-dimensional arrays and some tables:\nL2() = multimeasure(L2OnVectors(), transform=vec∘collect)\n\ny = rand(3, 5, 100)\nŷ = rand(3, 5, 100)\nweights = rand(100)\n@assert L2()(ŷ, y, weights) ≈\n   sum(vec(mean((ŷ - y).^2, dims=[1, 2])).*weights)/length(weights)\n\nusing Tables\ny = rand(3, 100)\nŷ = rand(3, 100)\nt = Tables.table(y') |> Tables.rowtable\nt̂ = Tables.table(ŷ') |> Tables.rowtable\n@assert L2()(t̂, t, weights) ≈\n   sum(vec(mean((ŷ - y).^2, dims=1)).*weights)/length(weights)\n\nnote: Note\nThe measure traits StatisticalMeasuresBase.observation_scitype(measure) (default=Union{}) and StatisticalMeasuresBase.can_consume_tables(measure) (default=false) are not forwarded from the atomic measure and must be explicitly overloaded for measures wrapped using multimeasure.\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.fussy_measure","page":"Methods","title":"StatisticalMeasuresBase.fussy_measure","text":"fussy_measure(measure; extra_check=nothing)\n\nReturn a new measure, fussy, with the same behavior as measure, except that calling fussy on data, or calling measuremnts on fussy and data, will will additionally:\n\nCheck that if weights or class_weights are specified, then measure supports them (see StatisticalMeasuresBase.check_weight_support)\nCheck that ŷ (predicted proxy), y (ground truth), weights and class_weights are compatible, from the point of view of observation counts and class pools, if relevant (see and StatisticalMeasuresBase.check_numobs and StatisticalMeasuresBase.check_pools).\nCall extra_check(measure, ŷ, y[, weights, class_weights]), unless extra_check==nothing. Note the first argument here is measure, not atomic_measure.\n\nDo not use fussy_measure unless both y and ŷ are expected to implement the MLUtils.jl getobs/numobs interface (e.g., are AbstractArrays)\n\nSee also StatisticalMeasuresBase.measurements, StatisticalMeasuresBase.is_measure\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.robust_measure","page":"Methods","title":"StatisticalMeasuresBase.robust_measure","text":"robust_measure(measure)\n\nReturn a new measure robust such that:\n\nweights and class_weights are silently treated as uniform (unit) if unsupported by measure\nif either weights or class_weights is nothing, it is as if the argument is omitted (interpreted as uniform)\n\nThis holds for all calls of the form robust(ŷ, y, weights, class_weights) or measurements(robust, ŷ, y, weights, class_weights) and otherwise the behavior of robust is the same as for measure.\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.Measure","page":"Methods","title":"StatisticalMeasuresBase.Measure","text":"Measure(m)\n\nConvert a measure-like object m to a measure in the sense of StatisticalMeasuresBase.jl; see StatisticalMeasuresBase.is_measure for the definition.\n\nTypically, Measure is applied to measures with pre-existing calling behaviour different from that specified by StatisticalMeasuresBase.jl.\n\nNew implementations\n\nTo make a measure-like object of type M wrappable by Measure, implement the appropriate methods below. The first and last are compulsory.\n\n(m::Measure{M})(ŷ, y)\n(m::Measure{M})(ŷ, y, weights)\n(m::Measure{M})(ŷ, y, class_weights::AbstractDict)\n(m::Measure{M}, ŷ, y, weights, class_weights)\nStatisticalMeasuresBase.measurements(m::Measure{M}, ŷ, y)\nStatisticalMeasuresBase.measurements(m::Measure{M}, ŷ, y, weights)\nStatisticalMeasuresBase.measurements(m::Measure{M}, ŷ, y, class_weights::AbstractDict)\nStatisticalMeasuresBase.measurements(m::Measure{M}, ŷ, y, weights, class_weights)\nStatisticalMeasuresBase.is_measure(m::Measure{M}) where M = true\n\nIn your implementations, you may use StatisticalMeasuresBase.unwrap to access the unwrapped object, i.e., StatisticalMeasuresBase.unwrap(Measure(m)) === m.\n\nSample implementation\n\nTo wrap the abs function as a measure that computes the absolute value of differences:\n\nimport StatisticalMeasuresBase as API\n\n(measure::API.Measure{typeof(abs)})(yhat, y) = API.unwrap(measure)(yhat - y)\nAPI.is_measure(::API.Measure{typeof(abs)}) = true\n\njulia> API.Measure(abs)(2, 5)\n3\n\n\n\n\n\n","category":"type"},{"location":"methods/#Unwrapping-2","page":"Methods","title":"Unwrapping","text":"","category":"section"},{"location":"methods/","page":"Methods","title":"Methods","text":"StatisticalMeasuresBase.unfussy\nStatisticalMeasuresBase.unwrap","category":"page"},{"location":"methods/#StatisticalMeasuresBase.unfussy","page":"Methods","title":"StatisticalMeasuresBase.unfussy","text":"unfussy(measure)\n\nReturn a version of measure with argument checks removed, if that is possible. Specifically, if measure == fussy_measure(atomic_measure), for some atomic_measure, then return atomic_measure. Otherwise, return measure.\n\nSee also StatisticalMeasuresBase.fussy_measure.\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.unwrap","page":"Methods","title":"StatisticalMeasuresBase.unwrap","text":"StatisticalMeasuresBase.unwrap(measure)\n\nRemove one layer of wrapping from measure. If not wrapped, return measure.\n\nSee also StatisticalMeasuresBase.unfussy.\n\n\n\n\n\n","category":"function"},{"location":"methods/#Traits-2","page":"Methods","title":"Traits","text":"","category":"section"},{"location":"methods/","page":"Methods","title":"Methods","text":"StatisticalMeasuresBase.is_measure\nStatisticalMeasuresBase.consumes_multiple_observations\nStatisticalMeasuresBase.can_report_unaggregated\nStatisticalMeasuresBase.kind_of_proxy\nStatisticalMeasuresBase.observation_scitype\nStatisticalMeasuresBase.can_consume_tables\nStatisticalMeasuresBase.supports_weights\nStatisticalMeasuresBase.supports_class_weights\nStatisticalMeasuresBase.orientation\nStatisticalMeasuresBase.external_aggregation_mode\nStatisticalMeasuresBase.human_name","category":"page"},{"location":"methods/#StatisticalMeasuresBase.is_measure","page":"Methods","title":"StatisticalMeasuresBase.is_measure","text":"StatisticalMeasuresBase.is_measure(m)\n\nReturns true if m is a measure, as defined below.\n\nAn object m has measure calling syntax if it is a function or other callable with the following signatures:\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights)\n\nOnly the first signature is obligatory.\n\nOf course m could be an instance of some type with parameters.\n\nIf, additionally, m returns an (aggregated) measurement, where y has the interpretation of one or more ground truth target observations, and ŷ corresponding to one or more predictions or proxies of predictions (such as probability distributions), then m is a measure.  The terms \"target\" and \"proxy\" are used here in the sense of LearnAPI.jl.\n\nWhat qualifies as a \"measurement\" is not formally defined, but this is typically a Real number; other use-cases are matrices (e.g., confusion matrices) and dictionaries (e.g., mutli-class true positive counts).\n\nArguments\n\nFor m to be a valid measure, it will handle arguments of one of the following forms:\n\ny is either:\na single ground truth observation of some variable, the \"target\", or\nan object implementing the getobs/numobs interface in MLUtils.jl, and consisting of multiple target observations\nŷ is correspondingly:\na single target prediction or proxy for a prediction, such as a probability distribution, or\nan object implementing the getobs/numobs interface in MLUtils.jl, and consisting of multiple target (proxy) predictions, with numobs(ŷ) == numobs(y) - or is a single object, such as a joint probability distribution. The latter case should be clarified by an appropriate StatisticalMeasuresBase.kind_of_proxy(measure) declaration.\nweights, applying only in the multiple observation case, is an arbitrary iterable collection with a length, generating n Real elements, where n ≥ MLUtils.numobs(y).\nclass_weights is an arbitrary AbstractDict with Real values, whose keys include all possible observations in y.\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.consumes_multiple_observations","page":"Methods","title":"StatisticalMeasuresBase.consumes_multiple_observations","text":"StatisticalMeasuresBase.consumes_multiple_observations(measure)\n\nReturns true if the ground truth target y appearing in calls like measure(ŷ, y) is expected to support the MLUtils.jl getobs/numobs interface, which includes all arrays and some tables.\n\nIf StatisticalMeasuresBase.kind_of_proxy(measure) <: LearnAPI.IID (the typical case) then a true value for this measure trait also implies ŷ is expected to be an MLUtils.jl data container with the same number of observations as y.\n\nNew implementations\n\nOverload this trait for a new measure type that consumes multiple observations, unless it has been constructed using multimeaure or is an StatisticalMeasuresBase.jl wrap thereof. The general fallback returns false but it is true for any multimeasure, and the value is propagated by other wrappers.\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.can_report_unaggregated","page":"Methods","title":"StatisticalMeasuresBase.can_report_unaggregated","text":"StatisticalMeasuresBase.can_report_unaggregated(measure)\n\nReturns true if measure can report individual measurements, one per ground truth observation. Such unaggregated measurements are obtained using measurements instead of directly calling the measure on data.\n\nIf the method returns false, measurements returns the single aggregated measurement returned by calling the measure on data, but repeated once for each ground truth observation.\n\nNew implementations\n\nOverloading the trait is optional and it is typically not overloaded. The general fallback returns false but it is true for any multimeasure, and the value is propagated by other wrappers.\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.kind_of_proxy","page":"Methods","title":"StatisticalMeasuresBase.kind_of_proxy","text":"StatisticalMeasuresBase.kind_of_proxy(measure)\n\nReturn the kind of proxy ŷ for target predictions expected in calls of the form measure(ŷ, y, args...; kwargs...).\n\nTypical return values are LearnAPI.Point(), when ŷ is expected to have the same form as y, or LearnAPI.Distribution(), when the observations in ŷ are expected to represent probability density/mass functions. For other kinds of proxy, see the LearnAPI.jl documentation.\n\nNew implementations\n\nOptional but strongly recommended. The return value must be a subtype of LearnAPI.KindOfProxy from the package LearnAPI.jl.\n\nThe fallback returns nothing.\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.observation_scitype","page":"Methods","title":"StatisticalMeasuresBase.observation_scitype","text":"StatisticalMeasuresBase.observation_scitype(measure)\n\nReturns an upper bound on the allowed scientific type of a single ground truth observation passed to measure. For more on scientific types, see the ScientificTypes.jl documentation.\n\nSpecifically, if the scitype of every element of observations = [MLUtils.eachobs(y)...] is bounded by the method value, then that guarantees that measure(ŷ, y; args...; kwargs...) will succeed, assuming y is suitably compatible with the other arguments.\n\nSupport for tabular data\n\nIf StatisticalMeasuresBase.can_consume_tables(measure) is true, then y can additionally be any table, so long as vec(collect(row)) makes sense for every row in observations (e.g., y is a DataFrame) and is bounded by the scitype returned by observation_scitype(measure).\n\nAll the behavior outlined above assumes StatisticalMeasuresBase.consumes_multiple_observations(measure) is true. Otherwise, the return value has no meaning.\n\nNew implementations\n\nOptional but strongly recommended for measures that consume multiple observations. The fallback returns Union{}.\n\nExamples of return values are Union{Finite,Missing}, for CategoricalValue observations with possible missing values, or AbstractArray{<:Infinite}, for observations that are arrays with either Integer or AbstractFloat eltype. Scientific types can be imported from ScientificTypesBase.jl; see also the ScientificTypes.jl documentation. .\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.can_consume_tables","page":"Methods","title":"StatisticalMeasuresBase.can_consume_tables","text":"StatisticalMeasuresBase.can_consume_tables(measure)\n\nReturn true if y and ŷ in a call like measure(ŷ, y) can be a certain kind of table (e.g., a DataFrame). See StatisticalMeasuresBase.observation_scitype for details.\n\nNew implementations\n\nOptional. The main use case is measures of the form multimeasure(atom, transform=vec∘collect), where atom is a measure consuming vectors. See multimeasure for an example. For such measures the trait can be overloaded to return true.\n\nThe fallback returns false.\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.supports_weights","page":"Methods","title":"StatisticalMeasuresBase.supports_weights","text":"StatisticalMeasuresBase.supports_weights(measure)\n\nReturn true if the measure supports per-observation weights, which must be AbstractVector{<:Real}.\n\nNew implementations\n\nThe fallback returns false. The trait is true for all multimeasures.\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.supports_class_weights","page":"Methods","title":"StatisticalMeasuresBase.supports_class_weights","text":"StatisticalMeasuresBase.supports_class_weights(measure)\n\nReturn true if the measure supports class weights, which must be dictionaries of Real values keyed on all possible values of targets y passed to the measure.\n\nNew implementations\n\nThe fallback returns false. The trait is true for all multimeasures.\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.orientation","page":"Methods","title":"StatisticalMeasuresBase.orientation","text":"StatisticalMeasuresBase.orientation(measure)\n\nReturns:\n\nStatisticalMeasuresBase.Score(), if measure is likely the basis of optimizations in which the measure value is always maximized\nStatisticalMeasuresBase.Loss(), if measure is likely the basis of optimizations in which the  measure value is always minimized\nStatisticalMeasuresBase.Unoriented(), in any other case\n\nNew implementations\n\nThis trait should be overloaded for measures likely to be used in optimization.\n\nThe fallback returns Unoriented().\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.external_aggregation_mode","page":"Methods","title":"StatisticalMeasuresBase.external_aggregation_mode","text":"StatisticalMeasuresBase.external_aggregation_mode(measure)\n\nReturns the preferred mode for aggregating measurements generated by applications of the measure on multiple sets of data. This can be useful to know when aggregating separate measurements in a cross-validation scheme. It is also the default aggregation mode used when wrapping a measure using multimeasure.\n\nSee also aggregate, multimeasure\n\nNew implementations\n\nThis optional trait has a fallback returning Mean(). Possible values are instances of subtypes of StatisticalMeasuresBase.AggregationMode.\n\n\n\n\n\n","category":"function"},{"location":"methods/#StatisticalMeasuresBase.human_name","page":"Methods","title":"StatisticalMeasuresBase.human_name","text":"StatisticalMeasuresBase.human_name(measure)\n\nA human-readable string representation of typeof(measure). Primarily intended for auto-generation of documentation.\n\nNew implementations\n\nOptional. A fallback takes the type name, inserts spaces and removes capitalization. For example, FScore becomes \"f score\". Better might be to overload the trait     to return \"F-score\".\n\n\n\n\n\n","category":"function"},{"location":"","page":"Overview","title":"Overview","text":"<script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n\n<div style=\"font-size:1.4em;font-weight:bold;\">\n  <a href=\"tutorial\"\n    style=\"color: #389826;\">Tutorial</a>           &nbsp;|&nbsp;\n  <a href=\"https://juliaai.github.io/StatisticalMeasuresBase.jl/dev/implementing_new_measures/#definitions\"\n    style=\"color: #9558B2;\">What is a measure?</a>\n</div>\n\n<span style=\"color: #9558B2;font-size:4.5em;\">\nStatisticalMeasuresBase.jl</span>\n<br>\n<span style=\"color: #9558B2;font-size:1.4em;font-style:italic;\">\nA Julia package for building production-ready measures (metrics) for statistics and machine learning</span>\n<br><br>","category":"page"},{"location":"#The-main-idea","page":"Overview","title":"The main idea","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Here's an example of a simple statistical measure, applied to a pair of scalars:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"l1(ŷ, y) = abs(ŷ - y)\ny = 5 # ground truth\nŷ = 2 # prediction\nl1(ŷ, y)","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Wrappers provided in this package extend the functionality of such measures. For example:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"using StatisticalMeasuresBase\nL1 = multimeasure(supports_missings_measure(l1), mode=Sum())\ny = [5, 6, missing]\nŷ = [6, 8, 7]\nweights = [1, 3, 9]\nL1(ŷ, y, weights) ≈ 1*l1(6, 5) + 3*l1(8, 6)","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"multitarget_L1 = multimeasure(L1, transform=vec∘collect)\n# 3 observations (last index is observation index):\ny = [1 2 3; 2 4 6]\nŷ = [2 3 4; 4 6 8]\nmultitarget_L1(ŷ, y, weights)","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"using DataFrames\ndf    = DataFrame(y', :auto)\ndf̂    = DataFrame(ŷ', :auto)\nmultitarget_L1(df̂, df, weights)","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Generate measurements for each observation with the measurements method:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"measurements(multitarget_L1, df̂, df, weights)","category":"page"},{"location":"#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"This package specifies an interface for statistical measures (metrics) such as classical loss functions, confusion matrices, and proper scoring rules. It also provides wrappers for extending their functionality. It does not implement actual measures. For a package that does, based on this interface, see StatisticalMeasures.jl.  The wrappers can also be applied to measures provided by other packages, such as LossFunctions.jl.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Specifically, this package provides:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"A measure wrapper multimeasure that leverages MLUtils.jl to broadcast a simple measure over multiple observations; the main use case is for extending a measure (e.g., function) that consumes single observations to measures consuming vectors, arrays or tables (multi-target measures).\nOther wrappers to add missing value support, argument checks, or to silently treat unsupported weights as uniform (good for application of a batch of measures with mixed degrees of weight support)\nmeasurements, a method to return unaggregated measurements\nA number of optional traits to articulate contracts useful for client packages; for example, optimization packages may only work with measures that overload the orientation trait.\naggregate, a multipurpose measurement aggregation tool.\nTechnical tools for implementing new measures, such as CompositeWeights, which combines per-observation weights and class weights into a single iterator.","category":"page"},{"location":"#Contents","page":"Overview","title":"Contents","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Tutorial\nMethods\nImplementing New Measures\nTools for Implementers","category":"page"},{"location":"implementing_new_measures/#Implementing-New-Measures","page":"Implementing New Measures","title":"Implementing New Measures","text":"","category":"section"},{"location":"implementing_new_measures/","page":"Implementing New Measures","title":"Implementing New Measures","text":"Use this section as a guide to what should be implemented by new measure types.","category":"page"},{"location":"implementing_new_measures/#definitions","page":"Implementing New Measures","title":"What's a measure?","text":"","category":"section"},{"location":"implementing_new_measures/","page":"Implementing New Measures","title":"Implementing New Measures","text":"In brief, a measure is a function, or other callable object, m, with the following calling syntax:","category":"page"},{"location":"implementing_new_measures/","page":"Implementing New Measures","title":"Implementing New Measures","text":"m(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights)","category":"page"},{"location":"implementing_new_measures/","page":"Implementing New Measures","title":"Implementing New Measures","text":"Only the first signature is obligatory. The argument y is some kind of \"ground truth\" and ŷ a corresponding \"prediction\". The return value will be an aggregated \"measurement\".  See StatisticalMeasuresBase.is_measure for details.","category":"page"},{"location":"implementing_new_measures/","page":"Implementing New Measures","title":"Implementing New Measures","text":"Of course m could be an instance of some type with parameters.","category":"page"},{"location":"implementing_new_measures/","page":"Implementing New Measures","title":"Implementing New Measures","text":"A wrapper Measure enables measure-like objects with different calling behavior to be regarded as StatisticalMeasuresBase.jl measures.","category":"page"},{"location":"implementing_new_measures/#Principal-methods","page":"Implementing New Measures","title":"Principal methods","text":"","category":"section"},{"location":"implementing_new_measures/","page":"Implementing New Measures","title":"Implementing New Measures","text":"method compulsory for new measures? fallback\ndirect callability (see above) yes \nStatisticalMeasuresBase.measurements no repeats n times the output of calling the measure","category":"page"},{"location":"implementing_new_measures/#traits","page":"Implementing New Measures","title":"Traits","text":"","category":"section"},{"location":"implementing_new_measures/","page":"Implementing New Measures","title":"Implementing New Measures","text":"A measure trait is just a function with single argument, measure, used to promise additional behavior.  A convenience macro @trait exists for overloading traits. Overloading traits, apart from is_measure, is optional, but generally recommended. See the table under Methods for a summary of the contracts implied by traits.","category":"page"},{"location":"implementing_new_measures/","page":"Implementing New Measures","title":"Implementing New Measures","text":"Mostly a measure wrapper, such as supports_missings_measure, just propagates trait values. See the last column of the table for special cases where you may want to consider overloading traits for wrapped measures.","category":"page"},{"location":"implementing_new_measures/","page":"Implementing New Measures","title":"Implementing New Measures","text":"method comment general fallback overload for wrapper?\nStatisticalMeasuresBase.is_measure(measure) overloading automatic if using @trait false no\nStatisticalMeasuresBase.consumes_multiple_observations(measure)  false no\nStatisticalMeasuresBase.can_report_unaggregated(measure)  false no\nStatisticalMeasuresBase.kind_of_proxy(measure) strongly recommended nothing maybe for multimeasure\nStatisticalMeasuresBase.observation_scitype(measure)  Union{} likely for multimeasure\nStatisticalMeasuresBase.can_consume_tables(measure) strongly recommended if supported false maybe for multimeasure\nStatisticalMeasuresBase.supports_weights(measure) strongly recommended if supported false no\nStatisticalMeasuresBase.supports_class_weights(measure) strongly recommended if supported false no\nStatisticalMeasuresBase.orientation(measure) strongly recommended Unoriented no\nStatisticalMeasuresBase.external_aggregation_mode(measure)  Mean() no\nStatisticalMeasuresBase.human_name(measure)  see docstring maybe","category":"page"},{"location":"tutorial/#Tutorial","page":"Tutorial","title":"Tutorial","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Read this tutorial to learn how to implement new measures using StatisticalMeasuresBase.jl. Refer to Implementing New Measures and other sections for technical details, bells and whistles.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The goal of this tutorial is to define a Huber loss function, HuberLoss(; delta=1), that consumes vectors of real ground truth observations/predictions, with support for weights, class weights and missing values; and a second measure MultitargetHuberLoss(; delta=1) that consumes matrices, tables or multidimensional arrays. To do so requires only that we implement a single Huber loss for scalars and apply appropriate measure wrappers.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"As we'll see, the most important wrapper to understand is the multimeasure wrapper.","category":"page"},{"location":"tutorial/#The-basics","page":"Tutorial","title":"The basics","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Let's start by defining a scalar Huber loss function:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"valley(a, delta=1) = abs(a) <= delta ? a^2/2 : delta*(abs(a) - delta/2)\nhuber(ŷ, y, delta=1) = valley(ŷ - y, delta)","category":"page"},{"location":"tutorial/#Huber-loss-type-for-scalar-input","page":"Tutorial","title":"Huber loss type for scalar input","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Since the Huber loss has a parameter, we create a struct, and make instances callable:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using StatisticalMeasuresBase\nimport StatisticalMeasuresBase as API\n\nstruct HuberLossOnScalars{T<:Real}\n    delta::T\nend\n(measure::HuberLossOnScalars)(ŷ, y) = huber(ŷ, y, measure.delta)\nAPI.is_measure(::HuberLossOnScalars) = true # recommended if `HuberLossOnScalars` is public-facing","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"measure = HuberLossOnScalars(0.5)\n@assert measure(7, 4) == huber(7, 4, 0.5)","category":"page"},{"location":"tutorial/#Huber-loss-for-vector-input","page":"Tutorial","title":"Huber loss for vector input","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"To get a Huber loss for vectors, we wrap the scalar measure using multimeasure, which broadcasts over MLUtils.eachobs((ŷ, y)) in call invocations. We also include a preliminary wrapping to support missing values:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"HuberLoss(delta) =\n    multimeasure(supports_missings_measure(HuberLossOnScalars(delta)))\nHuberLoss(; delta=1) = HuberLoss(delta)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"By default, a new measure has Mean() as its external aggregation mode, which you can inspect using the trait StatisticalMeasuresBase.external_aggregation_mode(measure). Wrappers, like support_missings_measure, forward such traits to the wrapped measure. The multimeasure wrapper uses MLUtils.jl's eachobs method to broadcast the atomic measure over oberservations and, by default, aggregates the result using the atomic measure's aggregation mode.","category":"page"},{"location":"tutorial/#Demonstration","page":"Tutorial","title":"Demonstration","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using Statistics\nŷ = [1, 2, missing]\ny = [7, 4, 6]\nweights = [1, 3, 2]\nclass_weights = Dict(7=>3.0, 4=>4.0, 6=>2.0)\n\nwts = weights .* (class_weights[η] for η in y)\n@assert HuberLoss(1)(ŷ, y, weights, class_weights) ≈\n    sum(wts[1:2] .* huber.(ŷ[1:2], y[1:2])) / length(wts)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Note the divisor length(weights) on the last line: The weighted measurement is not literally the weighted mean but the weighted mean scaled by the average value of the weights. To get the bone fide weighted mean, use multimeasure(..., mode=IMean()) instead. Another option is Sum(); see StatisticalMeasuresBase.AggregationMode for other options.","category":"page"},{"location":"tutorial/#Multi-target-Huber-loss","page":"Tutorial","title":"Multi-target Huber loss","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Here's the Huber loss for multi-targets (matrices or tables) which includes strict argument checks, and works for higher dimensional arrays as well (argument checks can be removed with unfussy(measure)):","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"MultitargetHuberLoss(args...; kwargs...) =\n    multimeasure(HuberLoss(args...; kwargs...), transform = vec∘collect) |> fussy_measure","category":"page"},{"location":"tutorial/#Demonstration-2","page":"Tutorial","title":"Demonstration","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Multi-targets (as matrices):","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"y       = rand(3, 20)\nŷ       = rand(3, 20)\nweights = rand(20)\nms = weights .* vec(mean(huber.(ŷ, y), dims=1))\n@assert measurements(MultitargetHuberLoss(), ŷ, y, weights) ≈ ms\n@assert MultitargetHuberLoss()(ŷ, y, weights) ≈  sum(ms)/length(weights)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Note the use of the measurements method, to return one measurement per observation, instead of an aggregate.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Mutli-targets (as tables):","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using DataFrames\ndf    = DataFrame(y', :auto)\ndf̂    = DataFrame(ŷ', :auto)\n@assert MultitargetHuberLoss()(df̂, df, weights) ≈ MultitargetHuberLoss()(df̂, df, weights)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Multi-dimensional arrays:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"y    = rand(2, 3, 20)\nŷ    = rand(2, 3, 20)\nweights = rand(20)\nms = weights .* vec(mean(huber.(ŷ, y), dims=[1, 2]))\n@assert measurements(MultitargetHuberLoss(), ŷ, y, weights) ≈ ms\n@assert MultitargetHuberLoss()(ŷ, y, weights) ≈  sum(ms)/length(weights)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Invalid arguments:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"class_weights = Dict()\nMultitargetHuberLoss()(ŷ, y, class_weights)\nERROR: ArgumentError: Class pool or value set is not compatible with the class_weight dictionary keys.","category":"page"},{"location":"tutorial/#Overloading-traits","page":"Tutorial","title":"Overloading traits","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Here's how to overload measure traits to make additional promises of behavior.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using ScientificTypesBase\n@trait HuberLossOnScalars orientation=Loss()\n\ntypeof(HuberLoss())","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"const HuberLossType = API.Multimeasure{\n    <:API.SupportsMissingsMeasure{\n    <:HuberLossOnScalars\n}}\n@trait(\n    HuberLossType,\n    observation_scitype = Union{Continuous,Missing},\n    human_name = \"Huber loss\",\n)\n\nAPI.observation_scitype(HuberLoss())","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"const MultitargetHuberLossType = API.FussyMeasure{<:API.Multimeasure{<:HuberLossType}}\n@trait(\n    MultitargetHuberLossType,\n    observation_scitype = AbstractArray{<:Union{Continuous,Missing}},\n    can_consume_tables = true,\n    human_name = \"multi-target Huber loss\",\n)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"note: Note\nWhile most wrappers forward atomic measure traits appropriately, StatisticalMeasuresBase.observation_scitype(measure) (default=Union{}) and StatisticalMeasuresBase.can_consume_tables(measure) (default=false) must be explicitly overloaded for measures wrapped using multimeasure.","category":"page"},{"location":"tutorial/#Improving-display-of-measures","page":"Tutorial","title":"Improving display of measures","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Because most useful measures are wraps of atomic measures, they don't display well:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"HuberLoss()","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"This can be improved using the @fix_show macro:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"@fix_show HuberLoss::HuberLossType\nHuberLoss()","category":"page"},{"location":"tutorial/#Macro-shortcut-(experimental)","page":"Tutorial","title":"Macro shortcut (experimental)","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The entire workflow above is equivalent to the code block below, except that HuberLoss is also fussy and MultitargetHuberLoss gets an additional keyword argument atomic_weights, for specifying weights per component of the vector-valued target (per column if y is a table). The loss functions also accept nothing for weights or class weights.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"You will need to try this in a new Julia session or change the loss name. See @combination for details.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"valley(a, delta=1) = abs(a) <= delta ? a^2/2 : delta*(abs(a) - delta/2)\nhuber(ŷ, y, delta=1) = valley(ŷ - y, delta)\n\nusing StatisticalMeasuresBase\nimport StatisticalMeasuresBase as API\nusing ScientificTypesBase\n\n@combination(\n    HuberLoss(; delta=1) = multimeasure(huber),\n    orientation =  Loss(),\n    observation_scitype = Continuous,\n    human_name = \"Huber loss\",\n)","category":"page"},{"location":"tutorial/#Demonstration-3","page":"Tutorial","title":"Demonstration","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"n = 10\ny = vcat(fill(1, n)', fill(1, n)', fill(1, n)')\nŷ = vcat(fill(1, n)', fill(2, n)', fill(3, n)')\nŷ - y","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"delta = 10\nvalley(1, delta)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"valley(2, delta)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"measure = MultitargetHuberLoss(delta=10, atomic_weights=[5, 4, 1])\n@assert measure(ŷ, y, fill(100, n)) ≈ (5*0 + 4*0.5 + 1*2.0)/3*100","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"API.observation_scitype(measure)","category":"page"}]
}
